{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day4_Logistic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7ZixCu93-Z"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubdhvk9U97af"
      },
      "source": [
        "## SKLearn을 이용한 Logistic Regression 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7hOippjiSWu"
      },
      "source": [
        "# 데이터 준비\n",
        "import os                            # 데이터 파일 경로 설정\n",
        "import csv                           # 데이터 파일 로드\n",
        "import numpy as np                   # numpy 행렬 조작\n",
        "import matplotlib.pyplot as plt      # 그래프 그리기(선택 사항)\n",
        "\n",
        "def Load_Iris_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[1]\n",
        "            x = [1] + [float(features)]    # x_data에 bias를 위한 1추가\n",
        "            y = float(line[0])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcoE64FB-pzS"
      },
      "source": [
        "_, x_train, y_train = Load_Iris_Dataset('./Iris_Train.csv')\n",
        "_, x_test, y_test = Load_Iris_Dataset('./Iris_Test.csv')\n",
        "\n",
        "\n",
        "# train 데이터 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Class\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7mBSxLf_agG"
      },
      "source": [
        "# Scikit-Learn 으로 학습\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97R1qGz0Acph"
      },
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = lr.predict(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "\n",
        "# 모델이 학습한 Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33OKDIX_kjH"
      },
      "source": [
        "# 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOXmn9BuQjXC"
      },
      "source": [
        "## Numerical Solution 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC3zXuW1v-r8"
      },
      "source": [
        "# 데이터 준비\n",
        "import os                            # 데이터 파일 경로 설정\n",
        "import csv                           # 데이터 파일 로드\n",
        "import numpy as np                   # numpy 행렬 조작\n",
        "import matplotlib.pyplot as plt      # 그래프 그리기(선택 사항)\n",
        "\n",
        "def Load_Iris_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[1]\n",
        "            x = [1] + [float(features)]    # x_data에 bias를 위한 1추가\n",
        "            y = float(line[0])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLffsZtJv-r8"
      },
      "source": [
        "_, x_train, y_train = Load_Iris_Dataset('./Iris_Train.csv')\n",
        "_, x_test, y_test = Load_Iris_Dataset('./Iris_Test.csv')\n",
        "\n",
        "\n",
        "# train 데이터 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Class\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7KurljjWkq"
      },
      "source": [
        "### 모델 정의\n",
        "1.   __\\_\\_init\\_\\___\n",
        "\n",
        "\n",
        "> *   인자: 모델 설정 \n",
        "*   출력: x\n",
        "*   기능: 모델 초기화\n",
        "\n",
        "> weight *W*를 random하게 initialization\n",
        "\n",
        "2.   __train__\n",
        "\n",
        "\n",
        "> *   입력: 학습데이터, 학습 설정\n",
        "*   출력: Loss \n",
        "*   기능: 데이터로 모델 학습\n",
        "\n",
        "> 매 epoch마다 전체 데이터에 대해 loss, grad 계산하여 학습\n",
        "\n",
        "\n",
        "3. __predict__\n",
        "\n",
        "> *   입력: 검증 데이터\n",
        "*   출력: 모델의 예측값\n",
        "*   기능: train로 학습된 모델로 검증, 예측값 생성\n",
        "\n",
        "> 검증 데이터에 대해 분류 예측 결과 산출 \n",
        "\n",
        "4. ___sigmoid__\n",
        "\n",
        "> *   입력: 실수형 numpy array\n",
        "*   출력: sigmoid를 취한 array\n",
        "*   기능: 주어진 array에 대한 모든 sigmoid 값 계산\n",
        "\n",
        "> $sigmoid(x) =\\frac{1}{ 1+e^{-(x)}}$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "mTCU7B8tkx2S"
      },
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, num_features, seed):\n",
        "        np.random.seed(seed)\n",
        "        self.W = np.random.rand(num_features, 1)\n",
        "\n",
        "    def train(self, train_x, train_y, num_epochs, learning_rate):\n",
        "        loss_memory = []\n",
        "        train_y = np.expand_dims(train_y, 1)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "          # prediction 계산 𝑿^𝑻 𝑾\n",
        "          prediction = np.matmul(train_x, self.W)\n",
        "\n",
        "          # sigmoid 적용\n",
        "          prob = self._sigmoid(prediction)\n",
        "\n",
        "          # Loss 계산\n",
        "          error = prob - train_y\n",
        "          loss = - np.mean(train_y * np.log(prob) + (1 - train_y) * np.log(1 - prob))\n",
        "\n",
        "          # Gradient 계산\n",
        "          grad = np.mean(train_x * error, axis=0, keepdims=True).T\n",
        "\n",
        "          # Weight Update\n",
        "          self.W -= grad * learning_rate\n",
        "\n",
        "          loss_memory.append(loss)\n",
        "        return loss_memory\n",
        "\n",
        "    def predict_prob(self, test_x):\n",
        "        prob = self._sigmoid(np.matmul(test_x, self.W))\n",
        "        return prob.flatten()\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        prob = self._sigmoid(np.matmul(test_x, self.W))\n",
        "        prob = prob.flatten()\n",
        "        y_pred_one_or_zero = []\n",
        "        for y in prob:\n",
        "            if y > 0.5:\n",
        "                y_pred_one_or_zero.append(1)\n",
        "            else:\n",
        "                y_pred_one_or_zero.append(0)\n",
        "        return y_pred_one_or_zero\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBt5hJWkzK8g"
      },
      "source": [
        "# Hyper-parameter 설정 및 학습\n",
        "num_epochs = 1000\n",
        "learning_rate = 1e-1\n",
        "seed = 2\n",
        "\n",
        "# Training\n",
        "num_data, num_features = x_train.shape\n",
        "\n",
        "model = LogisticRegression(num_features, seed)\n",
        "loss_memory = model.train(x_train, y_train, num_epochs, learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB_0wtckza9D"
      },
      "source": [
        "# Plot Loss\n",
        "x_axis = list(range(num_epochs))\n",
        "\n",
        "plt.plot(x_axis, loss_memory)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBqV4GWc1CzM"
      },
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = model.predict_prob(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "# 모델이 학습한 Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOjimBnwAYOM"
      },
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = model.predict(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "# 모델이 학습한 Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-1iNKRE1Ous"
      },
      "source": [
        "# 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b3rrYTkaTo2"
      },
      "source": [
        "## 스팸메일 데이터에서 SKLearn과 Numerical solution 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCGKydaicskb"
      },
      "source": [
        "# 데이터 준비\r\n",
        "import os                            # 데이터 파일 경로 설정\r\n",
        "import csv                           # 데이터 파일 로드\r\n",
        "import numpy as np                   # numpy 행렬 조작\r\n",
        "\r\n",
        "def Load_Spam_Dataset(filename):\r\n",
        "    with open(filename, 'r') as f:\r\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\r\n",
        "        header = next(csv_reader)\r\n",
        "\r\n",
        "        x_data = []\r\n",
        "        y_data = []\r\n",
        "        for line in csv_reader:\r\n",
        "            features = line[:-1]\r\n",
        "            x = [1] + list(map(float, features))   # x_data에 bias를 위한 1추가\r\n",
        "            y = float(line[-1])\r\n",
        "\r\n",
        "            x_data.append(x)\r\n",
        "            y_data.append(y)\r\n",
        "\r\n",
        "        x_array = np.array(x_data)\r\n",
        "        y_array = np.array(y_data)\r\n",
        "\r\n",
        "    return header, x_array, y_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8LMdIMVGm6R"
      },
      "source": [
        "_, x_train, y_train = Load_Spam_Dataset('./Spam_train.csv')\n",
        "_, x_test, y_test = Load_Spam_Dataset('./Spam_test.csv')\n",
        "\n",
        "print(x_train.shape) # 데이터 수, feature 수\n",
        "print(y_train.shape) # 데이터 수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8g0mAwfGm6T"
      },
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZK3WQ6xHRAR"
      },
      "source": [
        "# 평가\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "y_pred = lr.predict(x_test)\r\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh3xZtanICFT"
      },
      "source": [
        "# Numerical solution 구현 및 하이퍼파라미터 튜닝"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFTkOf31KUDv"
      },
      "source": [
        "## 유방암 데이터에서 SKLearn과 Numerical solution 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pACyXa90KUDx"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\r\n",
        "cancer = load_breast_cancer()\r\n",
        "print(cancer.feature_names) # feature 이름 출력\r\n",
        "\r\n",
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\r\n",
        "import numpy as np\r\n",
        "new_X = np.insert(cancer.data, 0, 1, axis=1)\r\n",
        "\r\n",
        "# train, test 나눔\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(new_X, cancer.target, test_size=0.3, shuffle=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Be9Ru0LE58"
      },
      "source": [
        "# Logistic regression\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "\r\n",
        "lr = LogisticRegression(max_iter=10000)\r\n",
        "lr.fit(x_train, y_train)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNk6ta3rKUDy"
      },
      "source": [
        "# 평가\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "y_pred = lr.predict(x_test)\r\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnYw8rUBLwg0"
      },
      "source": [
        "# Numerical solution 구현 및 하이퍼파라미터 튜닝"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}