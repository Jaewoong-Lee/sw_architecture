{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day4_Logistic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7ZixCu93-Z"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubdhvk9U97af"
      },
      "source": [
        "## SKLearnì„ ì´ìš©í•œ Logistic Regression ì‚´í´ë³´ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7hOippjiSWu"
      },
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "import os                            # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "import csv                           # ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
        "import numpy as np                   # numpy í–‰ë ¬ ì¡°ì‘\n",
        "import matplotlib.pyplot as plt      # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°(ì„ íƒ ì‚¬í•­)\n",
        "\n",
        "def Load_Iris_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # íŒŒì¼ ë¡œë“œ\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[1]\n",
        "            x = [1] + [float(features)]    # x_dataì— biasë¥¼ ìœ„í•œ 1ì¶”ê°€\n",
        "            y = float(line[0])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcoE64FB-pzS"
      },
      "source": [
        "_, x_train, y_train = Load_Iris_Dataset('./Iris_Train.csv')\n",
        "_, x_test, y_test = Load_Iris_Dataset('./Iris_Test.csv')\n",
        "\n",
        "\n",
        "# train ë°ì´í„° ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Class\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7mBSxLf_agG"
      },
      "source": [
        "# Scikit-Learn ìœ¼ë¡œ í•™ìŠµ\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97R1qGz0Acph"
      },
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = lr.predict(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "\n",
        "# ëª¨ë¸ì´ í•™ìŠµí•œ Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33OKDIX_kjH"
      },
      "source": [
        "# í‰ê°€\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOXmn9BuQjXC"
      },
      "source": [
        "## Numerical Solution êµ¬í˜„"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC3zXuW1v-r8"
      },
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\n",
        "import os                            # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "import csv                           # ë°ì´í„° íŒŒì¼ ë¡œë“œ\n",
        "import numpy as np                   # numpy í–‰ë ¬ ì¡°ì‘\n",
        "import matplotlib.pyplot as plt      # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°(ì„ íƒ ì‚¬í•­)\n",
        "\n",
        "def Load_Iris_Dataset(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        csv_reader = csv.reader(f)                  # íŒŒì¼ ë¡œë“œ\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            features = line[1]\n",
        "            x = [1] + [float(features)]    # x_dataì— biasë¥¼ ìœ„í•œ 1ì¶”ê°€\n",
        "            y = float(line[0])\n",
        "\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "    return header, x_array, y_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLffsZtJv-r8"
      },
      "source": [
        "_, x_train, y_train = Load_Iris_Dataset('./Iris_Train.csv')\n",
        "_, x_test, y_test = Load_Iris_Dataset('./Iris_Test.csv')\n",
        "\n",
        "\n",
        "# train ë°ì´í„° ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Class\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7KurljjWkq"
      },
      "source": [
        "### ëª¨ë¸ ì •ì˜\n",
        "1.   __\\_\\_init\\_\\___\n",
        "\n",
        "\n",
        "> *   ì¸ì: ëª¨ë¸ ì„¤ì • \n",
        "*   ì¶œë ¥: x\n",
        "*   ê¸°ëŠ¥: ëª¨ë¸ ì´ˆê¸°í™”\n",
        "\n",
        "> weight *W*ë¥¼ randomí•˜ê²Œ initialization\n",
        "\n",
        "2.   __train__\n",
        "\n",
        "\n",
        "> *   ì…ë ¥: í•™ìŠµë°ì´í„°, í•™ìŠµ ì„¤ì •\n",
        "*   ì¶œë ¥: Loss \n",
        "*   ê¸°ëŠ¥: ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "> ë§¤ epochë§ˆë‹¤ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ loss, grad ê³„ì‚°í•˜ì—¬ í•™ìŠµ\n",
        "\n",
        "\n",
        "3. __predict__\n",
        "\n",
        "> *   ì…ë ¥: ê²€ì¦ ë°ì´í„°\n",
        "*   ì¶œë ¥: ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’\n",
        "*   ê¸°ëŠ¥: trainë¡œ í•™ìŠµëœ ëª¨ë¸ë¡œ ê²€ì¦, ì˜ˆì¸¡ê°’ ìƒì„±\n",
        "\n",
        "> ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ ë¶„ë¥˜ ì˜ˆì¸¡ ê²°ê³¼ ì‚°ì¶œ \n",
        "\n",
        "4. ___sigmoid__\n",
        "\n",
        "> *   ì…ë ¥: ì‹¤ìˆ˜í˜• numpy array\n",
        "*   ì¶œë ¥: sigmoidë¥¼ ì·¨í•œ array\n",
        "*   ê¸°ëŠ¥: ì£¼ì–´ì§„ arrayì— ëŒ€í•œ ëª¨ë“  sigmoid ê°’ ê³„ì‚°\n",
        "\n",
        "> $sigmoid(x) =\\frac{1}{ 1+e^{-(x)}}$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "mTCU7B8tkx2S"
      },
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, num_features, seed):\n",
        "        np.random.seed(seed)\n",
        "        self.W = np.random.rand(num_features, 1)\n",
        "\n",
        "    def train(self, train_x, train_y, num_epochs, learning_rate):\n",
        "        loss_memory = []\n",
        "        train_y = np.expand_dims(train_y, 1)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "          # prediction ê³„ì‚° ğ‘¿^ğ‘» ğ‘¾\n",
        "          prediction = np.matmul(train_x, self.W)\n",
        "\n",
        "          # sigmoid ì ìš©\n",
        "          prob = self._sigmoid(prediction)\n",
        "\n",
        "          # Loss ê³„ì‚°\n",
        "          error = prob - train_y\n",
        "          loss = - np.mean(train_y * np.log(prob) + (1 - train_y) * np.log(1 - prob))\n",
        "\n",
        "          # Gradient ê³„ì‚°\n",
        "          grad = np.mean(train_x * error, axis=0, keepdims=True).T\n",
        "\n",
        "          # Weight Update\n",
        "          self.W -= grad * learning_rate\n",
        "\n",
        "          loss_memory.append(loss)\n",
        "        return loss_memory\n",
        "\n",
        "    def predict_prob(self, test_x):\n",
        "        prob = self._sigmoid(np.matmul(test_x, self.W))\n",
        "        return prob.flatten()\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        prob = self._sigmoid(np.matmul(test_x, self.W))\n",
        "        prob = prob.flatten()\n",
        "        y_pred_one_or_zero = []\n",
        "        for y in prob:\n",
        "            if y > 0.5:\n",
        "                y_pred_one_or_zero.append(1)\n",
        "            else:\n",
        "                y_pred_one_or_zero.append(0)\n",
        "        return y_pred_one_or_zero\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBt5hJWkzK8g"
      },
      "source": [
        "# Hyper-parameter ì„¤ì • ë° í•™ìŠµ\n",
        "num_epochs = 1000\n",
        "learning_rate = 1e-1\n",
        "seed = 2\n",
        "\n",
        "# Training\n",
        "num_data, num_features = x_train.shape\n",
        "\n",
        "model = LogisticRegression(num_features, seed)\n",
        "loss_memory = model.train(x_train, y_train, num_epochs, learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB_0wtckza9D"
      },
      "source": [
        "# Plot Loss\n",
        "x_axis = list(range(num_epochs))\n",
        "\n",
        "plt.plot(x_axis, loss_memory)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBqV4GWc1CzM"
      },
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = model.predict_prob(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "# ëª¨ë¸ì´ í•™ìŠµí•œ Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOjimBnwAYOM"
      },
      "source": [
        "# train dataì— ëŒ€í•œ í•™ìŠµ ëª¨ë¸ ì‹œê°í™”\n",
        "is_virginica_x = x_train[y_train == 1]\n",
        "is_virginica_y = y_train[y_train == 1]\n",
        "\n",
        "not_virginica_x = x_train[y_train == 0]\n",
        "not_virginica_y = y_train[y_train == 0]\n",
        "\n",
        "plot_feat = np.linspace(0, 3, 100).reshape(-1, 1)\n",
        "plot_x = np.insert(plot_feat, 0, 1, axis=1)\n",
        "plot_prob = model.predict(plot_x)\n",
        "\n",
        "plt.scatter(is_virginica_x[:, 1], is_virginica_y, color='b', label='Iris-Virginica')\n",
        "plt.scatter(not_virginica_x[:, 1], not_virginica_y, color='r', label='Not Iris-Virginica')\n",
        "\n",
        "# ëª¨ë¸ì´ í•™ìŠµí•œ Probability\n",
        "plt.plot(plot_feat, plot_prob, 'g-', label='Hypothesis')\n",
        "\n",
        "plt.xlabel(\"Petal width\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-1iNKRE1Ous"
      },
      "source": [
        "# í‰ê°€\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b3rrYTkaTo2"
      },
      "source": [
        "## ìŠ¤íŒ¸ë©”ì¼ ë°ì´í„°ì—ì„œ SKLearnê³¼ Numerical solution ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCGKydaicskb"
      },
      "source": [
        "# ë°ì´í„° ì¤€ë¹„\r\n",
        "import os                            # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\r\n",
        "import csv                           # ë°ì´í„° íŒŒì¼ ë¡œë“œ\r\n",
        "import numpy as np                   # numpy í–‰ë ¬ ì¡°ì‘\r\n",
        "\r\n",
        "def Load_Spam_Dataset(filename):\r\n",
        "    with open(filename, 'r') as f:\r\n",
        "        csv_reader = csv.reader(f)                  # íŒŒì¼ ë¡œë“œ\r\n",
        "        header = next(csv_reader)\r\n",
        "\r\n",
        "        x_data = []\r\n",
        "        y_data = []\r\n",
        "        for line in csv_reader:\r\n",
        "            features = line[:-1]\r\n",
        "            x = [1] + list(map(float, features))   # x_dataì— biasë¥¼ ìœ„í•œ 1ì¶”ê°€\r\n",
        "            y = float(line[-1])\r\n",
        "\r\n",
        "            x_data.append(x)\r\n",
        "            y_data.append(y)\r\n",
        "\r\n",
        "        x_array = np.array(x_data)\r\n",
        "        y_array = np.array(y_data)\r\n",
        "\r\n",
        "    return header, x_array, y_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8LMdIMVGm6R"
      },
      "source": [
        "_, x_train, y_train = Load_Spam_Dataset('./Spam_train.csv')\n",
        "_, x_test, y_test = Load_Spam_Dataset('./Spam_test.csv')\n",
        "\n",
        "print(x_train.shape) # ë°ì´í„° ìˆ˜, feature ìˆ˜\n",
        "print(y_train.shape) # ë°ì´í„° ìˆ˜"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8g0mAwfGm6T"
      },
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZK3WQ6xHRAR"
      },
      "source": [
        "# í‰ê°€\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "y_pred = lr.predict(x_test)\r\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh3xZtanICFT"
      },
      "source": [
        "# Numerical solution êµ¬í˜„ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFTkOf31KUDv"
      },
      "source": [
        "## ìœ ë°©ì•” ë°ì´í„°ì—ì„œ SKLearnê³¼ Numerical solution ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pACyXa90KUDx"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\r\n",
        "cancer = load_breast_cancer()\r\n",
        "print(cancer.feature_names) # feature ì´ë¦„ ì¶œë ¥\r\n",
        "\r\n",
        "# biasë¥¼ í•œë²ˆì— ê³„ì‚°í•˜ê¸° ìœ„í•´, 1ì„ Xì— ì¶”ê°€í•´ ì¤ë‹ˆë‹¤.\r\n",
        "import numpy as np\r\n",
        "new_X = np.insert(cancer.data, 0, 1, axis=1)\r\n",
        "\r\n",
        "# train, test ë‚˜ëˆ”\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(new_X, cancer.target, test_size=0.3, shuffle=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Be9Ru0LE58"
      },
      "source": [
        "# Logistic regression\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "\r\n",
        "lr = LogisticRegression(max_iter=10000)\r\n",
        "lr.fit(x_train, y_train)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNk6ta3rKUDy"
      },
      "source": [
        "# í‰ê°€\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "y_pred = lr.predict(x_test)\r\n",
        "print('Test Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnYw8rUBLwg0"
      },
      "source": [
        "# Numerical solution êµ¬í˜„ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}