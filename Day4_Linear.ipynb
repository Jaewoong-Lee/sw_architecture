{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day4_Linear.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7ZixCu93-Z"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubdhvk9U97af"
      },
      "source": [
        "## SKLearn을 이용한 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcoE64FB-pzS"
      },
      "source": [
        "# 데이터 준비\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# 데이터 시각화\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JrDghIv_xTI"
      },
      "source": [
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "import numpy as np\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7mBSxLf_agG"
      },
      "source": [
        "# Scikit-Learn 으로 학습\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97R1qGz0Acph"
      },
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], simple_linear.predict(train_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SmveKY8BnpE"
      },
      "source": [
        "# test data에 대한 학습 모델 시각화\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], simple_linear.predict(test_x), 'r',  label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33OKDIX_kjH"
      },
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOXmn9BuQjXC"
      },
      "source": [
        "## Linear Regression의 Numerical Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z21Sbgy2QjXC"
      },
      "source": [
        "# 데이터 준비\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# 데이터 시각화\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDW_fJnfQjXD"
      },
      "source": [
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "import numpy as np\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfuvYeagQ7Hd"
      },
      "source": [
        "class LinearRegression_gd:\n",
        "    def __init__(self, num_features, seed):\n",
        "        np.random.seed(seed)\n",
        "        self.W = np.random.rand(num_features, 1)\n",
        "        \n",
        "    def train(self, train_x, train_y, num_epochs, learning_rate):\n",
        "        num_data, num_features = train_x.shape\n",
        "\n",
        "        loss_memory = []\n",
        "        train_y = np.expand_dims(train_y, 1)\n",
        "\n",
        "        for i in range(num_epochs):\n",
        "\n",
        "            # prediction 계산\n",
        "            prediction = np.matmul(train_x, self.W)\n",
        "\n",
        "            # Error 및 Loss 계산\n",
        "            error = prediction - train_y\n",
        "            loss = np.mean(error * error) / 2\n",
        "\n",
        "            # Gradient 계산 \n",
        "            gradient= np.mean(train_x * error, axis=0, keepdims=True).T # 𝝏𝑳(𝒙, 𝑾)/𝝏𝑾\n",
        "\n",
        "            # Weight Update\n",
        "            # gradient, learning_rate 활용하여 self.W 업데이트\n",
        "            self.W -= learning_rate * gradient\n",
        "\n",
        "            # Loss ‘loss_memory’에 추가\n",
        "            loss_memory.append(loss)\n",
        "\n",
        "        # ‘loss_memory’ 반환\n",
        "        return loss_memory\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        pred = np.matmul(test_x, self.W).squeeze()\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htEMq4AaQjXD"
      },
      "source": [
        "# Hyper-parameter\n",
        "num_epochs = 1500\n",
        "learning_rate = 0.01\n",
        "seed = 15\n",
        "\n",
        "num_data, num_features = train_x.shape\n",
        "model = LinearRegression_gd(num_features, seed)\n",
        "loss_memory = model.train(train_x, train_y, num_epochs, learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXxV3FF4UfJ-"
      },
      "source": [
        "# Plot Loss\n",
        "x_axis = list(range(num_epochs))\n",
        "\n",
        "plt.plot(x_axis, loss_memory)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZmAouvrQjXD"
      },
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], model.predict(train_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYFICMDzQjXD"
      },
      "source": [
        "# test data에 대한 학습 모델 시각화\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], model.predict(test_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5dlfkkLQjXD"
      },
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = model.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = model.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omIluYozJrBD"
      },
      "source": [
        "## Linear Regression의 Analytical Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4Mnm49oL3EW"
      },
      "source": [
        "# 데이터 준비\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=100, n_features=1,\n",
        "                       bias=100, noise=40, random_state=1)\n",
        "\n",
        "\n",
        "# 데이터 시각화\n",
        "plt.scatter(X, y, label=\"data\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM5xuBPtL3Ed"
      },
      "source": [
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "import numpy as np\n",
        "new_X = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, y, test_size=0.3, shuffle=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IayUx_RkL3Ee"
      },
      "source": [
        "# Normal Equation \n",
        "first = np.linalg.inv(np.matmul(train_x.T, train_x))\n",
        "second = np.matmul(train_x.T, train_y)\n",
        "W = np.matmul(first, second)\n",
        "\n",
        "pred_train = np.matmul(train_x, W)\n",
        "pred_test = np.matmul(test_x, W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJAsqG1yL3Ee"
      },
      "source": [
        "# train data에 대한 학습 모델 시각화\n",
        "plt.scatter(train_x[:,1], train_y, label=\"train data\")\n",
        "plt.plot(train_x[:,1], pred_train, 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3hrVCdbL3Ef"
      },
      "source": [
        "# test data에 대한 학습 모델 시각화\n",
        "plt.scatter(test_x[:,1], test_y, label=\"test data\")\n",
        "plt.plot(test_x[:,1], pred_test, 'r',  label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOLEXknAL3Ef"
      },
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "print(\"Train RMSE =\", RMSE(pred_train, train_y))\n",
        "\n",
        "print(\"Test RMSE =\", RMSE(pred_test, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b3rrYTkaTo2"
      },
      "source": [
        "## 당뇨병 데이터에서, SKLearn, Numerical Solution, Analytical Solution 비교\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNowAJb-uO30"
      },
      "source": [
        "# 데이터 불러오기\n",
        "from sklearn.datasets import load_diabetes\n",
        "datasets = load_diabetes()\n",
        "\n",
        "# bias를 한번에 계산하기 위해, 1을 X에 추가해 줍니다.\n",
        "import numpy as np\n",
        "new_X = np.insert(datasets.data, 0, 1, axis=1)\n",
        "\n",
        "# train, test 나눔\n",
        "train_x, test_x, train_y, test_y = train_test_split(new_X, datasets.target, test_size=0.3, shuffle=True, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb0cYU3guO31"
      },
      "source": [
        "# Scikit-Learn 으로 학습\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37CrFS9nu05e"
      },
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJcur2f1xopy"
      },
      "source": [
        "# Analytical Solution 코드 추가하기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j8ZBD_Sxr4n"
      },
      "source": [
        "# Numerical Solution 코드 추가하기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mUPo4utx6MM"
      },
      "source": [
        "## 행복지수 데이터에서, SKLearn, Numerical Solution, Analytical Solution 비교\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd7-rfh8yUOX"
      },
      "source": [
        "import numpy as np\r\n",
        "import os                            # 데이터 파일 경로 설정\r\n",
        "import csv                           # 데이터 파일 로드\r\n",
        "\r\n",
        "def Load_Dataset(filename):\r\n",
        "    with open(filename, 'r') as f:\r\n",
        "        csv_reader = csv.reader(f)                  # 파일 로드\r\n",
        "        header = next(csv_reader)\r\n",
        "\r\n",
        "        x_data = []\r\n",
        "        y_data = []\r\n",
        "        for line in csv_reader:\r\n",
        "            features = line[6:]\r\n",
        "            x = [1.0] + [float(i) for i in features]\r\n",
        "            y = float(line[2])\r\n",
        "            x_data.append(x)\r\n",
        "            y_data.append(y)\r\n",
        "\r\n",
        "        x_array = np.array(x_data)\r\n",
        "        y_array = np.array(y_data)\r\n",
        "\r\n",
        "    return header, x_array, y_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0noCMGByG9x"
      },
      "source": [
        "# 데이터 불러오기\n",
        "_, train_x, train_y = Load_Dataset('/content/happiness_train.csv')\n",
        "_, test_x, test_y = Load_Dataset('/content/happiness_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYWHZ0ZuyG92"
      },
      "source": [
        "# Scikit-Learn 으로 학습\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "simple_linear = LinearRegression()\n",
        "simple_linear.fit(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTX8AXGHyG93"
      },
      "source": [
        "# 평가\n",
        "def RMSE(pred, target):\n",
        "  error = pred - target\n",
        "  square = error * error\n",
        "  mean = np.mean(square)\n",
        "  root = np.sqrt(mean)\n",
        "  return root\n",
        "\n",
        "pred = simple_linear.predict(train_x)\n",
        "print(\"Train RMSE =\", RMSE(pred, train_y))\n",
        "\n",
        "pred = simple_linear.predict(test_x)\n",
        "print(\"Test RMSE =\", RMSE(pred, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P01_FrVb1GpI"
      },
      "source": [
        "# Analytical Solution 코드 추가하기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV89dFZb1GpO"
      },
      "source": [
        "# Numerical Solution 코드 추가하기"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}